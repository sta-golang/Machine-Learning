## 决策树算法
![](https://img.shields.io/badge/author-TheSevenSky-blue) ![](https://img.shields.io/badge/build-passing-yellow) ![](https://img.shields.io/badge/Release-Development-red)

决策树算法是根据一系列规则对数据进行分类的过程。
决策树分为回归决策树和分类决策树

### 实现

下面给出一个简单的例子 根据这个人的收入情况来判断是否可以借款给这个人
![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1597626145,3654585987&fm=26&gp=0.jpg)


#### 构建过程

- （1）树从代表训练样本的根节点开始
- （2）如果样本都在同一分类中，则结点为叶子节点
- （3）否则，算法选择最优分类能力的属性作为决策树的当前节点
- （4）根据当前决策结点属性取值不同，将训练样本数据分为若干子集，每个取值形成一个分支，有几个取值就形成几个分支。
- （5）针对步骤（4）得到的每一个子集重复进行（1） （2） （3）递归的划分样本上的决策树。一旦一个属性只出现在一个结点上，就不必在该结点的任何子结点考虑它。

#### 例子
 
 某公司每一个月都要举办一场活动， 但是需要考虑到天气 湿度 温度 风速来决定是否要举办活动
 下列有4个属性来表示否是要举办活动
 
 | 天气 | 温度 | 湿度 | 风速 | 是否举办活动 |
 | :------: | :------: | :------: | :------: | :------: | 
 | 晴 | 炎热 | 高 | 弱 | 是 |
 | 晴 | 炎热 | 高 | 强 | 否 |
 | 阴 | 炎热 | 高 | 弱 | 是 |
 | 雨 | 寒冷 | 正常 | 弱 | 是 |
 | 雨 | 寒冷 | 正常 | 强 | 否 |
 | 阴 | 寒冷 | 正常 | 强 | 是 |
 | 晴 | 适中 | 高 | 弱 | 否 |
 | 晴 | 寒冷 | 正常 | 弱 | 是 |
 | 雨 | 适中 | 正常 | 弱 | 是 |
 | 晴 | 适中 | 正常 | 强 | 是 |
 | 阴 | 炎热 | 正常 | 弱 | 否 |
 | 雨 | 适中 | 高 | 强 | 否 |

数据集具体可以看 data.go<br/>
天气 : 晴（2） 阴（1） 雨（0）<br/>
温度 炎热（2） 适中（1） 寒冷（0）<br/>
湿度 高（1） 正常（0）<br/>
风速 强（1） 弱（0）<br/>
举办活动 （yes） 不举办活动（no）<br/>

<hr/>
#### 计算公式

**信息熵**

![](https://pic2.zhimg.com/v2-5b13d6faf786046b39f2d99fb0ed43a3_1440w.jpg?source=172ae18b)

例如 上列天气又三种情况

```go
晴天出现了5次 是的标签有3个 否有2个 对应的熵如下
E(天气|晴) = -5/12 * [ -3/5 * log2(3/5) - 2/5 * log2(2/5) ] = 0.406

 阴出现3次 是有2个 否有1个
E(天气|阴) = -3/12 * [ -2/3 * log2(2/3) - 1/3 * log2(1/3)] = 0.2296

同理 雨天
E(天气|雨) = 0.3333

E(天气) = E(天气|晴) + E(天气|雨) + E(天气|阴) = 0.9675

总的信息熵如下：
    数据有12个样本其中 是的标签有7个 否有5个
    E = -7/12 * log2(7/12) - 5/12 * log2(5/12) = 0.9799

同理可算得
    E(温度) = 0.9371
    E(湿度) = 0.9080
    E(风速) = 0.9080

信息增熵的计算公式为 E - E(特征)
例如 风速的信息增熵为 g(风速) = 0.9799 - 0.9080 = 0.0719


```
如何选择每一步的分支 就只需要选择信息增熵最大的一步就可以
比如第一步可以选择风速或者湿度
因为风速和湿度算出来的信息增熵是最大的